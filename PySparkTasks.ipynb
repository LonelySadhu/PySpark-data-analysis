{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   @@@@@@@     @      @    @  @   #\n",
    "#   @  @  @    @ @      @  @       #\n",
    "#      @  @   @   @      @@    @   #\n",
    "#      @     @@@@@@@    @  @   @   #\n",
    "#      @    @       @  @    @  @   #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, в этой практике мы с вами применим наши знания по PySpark и постараемся изучить что-то новое в процессе выполнения.\n",
    "<br>В занятии используется датасет собранный на основе данных <a href=\"https://www.kaggle.com/chicago/chicago-taxi-rides-2016\">Chicago Taxi Rides 2016</a>\n",
    "<br>Полная <a href=\"https://spark.apache.org/docs/latest/api/python/index.html\">документация PySpark</a>.\n",
    "<br>Схема данны:\n",
    "<br>|-- taxi_id = идентификатор таксиста\n",
    "<br>|-- trip_start_timestamp = время начала поездки\n",
    "<br>|-- trip_end_timestamp = время окончания поездки\n",
    "<br>|-- trip_seconds = время длительности поездки в секундах\n",
    "<br>|-- trip_miles = мили проиденные во время поездки\n",
    "<br>|-- fare = транспортные расходы\n",
    "<br>|-- tips = назначенные чаевые\n",
    "<br>|-- trip_total = общая стоимость поездки\n",
    "<br>|-- payment_type = тип оплаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('PySparkTasks').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.session.timeZone\", \"GMT+3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://4c178745a5f4:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkTasks</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc40b6799a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week3/spark-tasks/taxi_data.parquet\">taxi_data.parquet</a> и загрузите используя <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame\">SparkAPI</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option('header', 'true').parquet('taxi_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№1 Посчитайте количество загруженных строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2540712"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------+------------+----------+-----+-----+----------+------------+\n",
      "|taxi_id|trip_start_timestamp| trip_end_timestamp|trip_seconds|trip_miles| fare| tips|trip_total|payment_type|\n",
      "+-------+--------------------+-------------------+------------+----------+-----+-----+----------+------------+\n",
      "|   5240| 2016-12-15 23:45:00|2016-12-16 00:00:00|         900|       2.5|10.75| 2.45|      14.7| Credit Card|\n",
      "|   1215| 2016-12-12 07:15:00|2016-12-12 07:15:00|         240|       0.4|  5.0|  3.0|       9.5| Credit Card|\n",
      "|   3673| 2016-12-16 16:30:00|2016-12-16 17:00:00|        2400|      10.7| 31.0|  0.0|      31.0|        Cash|\n",
      "|   5400| 2016-12-16 08:45:00|2016-12-16 09:00:00|         300|       0.0| 5.25|  2.0|      7.25| Credit Card|\n",
      "|   1257| 2016-12-03 18:45:00|2016-12-03 18:45:00|         360|       0.3|  5.0|  0.0|       5.0|        Cash|\n",
      "|   4666| 2016-12-30 18:00:00|2016-12-30 18:45:00|        2400|      18.2|46.75|10.15|      61.4| Credit Card|\n",
      "|   5998| 2016-12-16 07:15:00|2016-12-16 07:45:00|        1800|      18.4| 45.0|11.25|     56.25| Credit Card|\n",
      "|   2538| 2016-12-31 17:15:00|2016-12-31 17:15:00|         540|       0.0| 6.75|  0.0|      7.75|        Cash|\n",
      "|   6594| 2016-12-17 12:00:00|2016-12-17 12:00:00|         153|      0.47|  4.5|  1.0|       6.0| Credit Card|\n",
      "|   7864| 2016-12-03 19:45:00|2016-12-03 20:00:00|         780|       2.4| 10.5|  2.0|      12.5| Credit Card|\n",
      "|    400| 2016-12-06 15:30:00|2016-12-06 16:30:00|        3120|      10.9|31.75| 7.93|     40.18| Credit Card|\n",
      "|   6482| 2016-12-09 09:30:00|2016-12-09 09:30:00|         660|      1.32| 7.75|  2.0|     10.25| Credit Card|\n",
      "|   5856| 2016-12-29 18:45:00|2016-12-29 19:00:00|         300|       0.0| 5.25|  0.0|      6.75|        Cash|\n",
      "|   7211| 2016-12-12 22:30:00|2016-12-12 23:00:00|        1320|      14.1| 36.0|  0.0|      41.0|        Cash|\n",
      "|   1094| 2016-12-10 21:00:00|2016-12-10 21:00:00|         540|       1.4| 6.75|  4.0|     10.75| Credit Card|\n",
      "|   6591| 2016-12-22 22:45:00|2016-12-22 23:00:00|         480|       1.7| 7.75|  0.0|      7.75|        Cash|\n",
      "|   6514| 2016-12-30 11:00:00|2016-12-30 11:00:00|         480|       1.5|  7.5|  0.0|       7.5|        Cash|\n",
      "|   8267| 2016-12-17 04:15:00|2016-12-17 04:15:00|         360|       1.9| 7.75|  4.0|     13.25| Credit Card|\n",
      "|   8002| 2016-12-19 12:15:00|2016-12-19 12:15:00|         300|       0.9|  6.0|  2.0|       8.5| Credit Card|\n",
      "|   2718| 2016-12-19 10:15:00|2016-12-19 10:45:00|        1920|       5.6|18.75|  0.0|     18.75|        Cash|\n",
      "+-------+--------------------+-------------------+------------+----------+-----+-----+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- taxi_id: integer (nullable = true)\n",
      " |-- trip_start_timestamp: timestamp (nullable = true)\n",
      " |-- trip_end_timestamp: timestamp (nullable = true)\n",
      " |-- trip_seconds: integer (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- trip_total: double (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим схему данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№2 Чему равна корреляция и ковариация между длиной маршрута и ценой за поездку? Ответ округлите до 5 знаков после запятой.\n",
    "<br>Подробнее <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.corr\">corr</a> & <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.cov\">cov</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44816"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.corr('trip_miles', 'trip_total'),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.96914"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.cov('trip_miles', 'trip_total'),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№3 Найдите количество, среднее, cреднеквадратическое отклонение, минимум и максимум для длины маршрута и цены за поездку? Ответ округлите до 1 знака после запятой. Подробнее <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.describe\">describe</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+---------------+\n",
      "|summary|trip_total_desc|trip_miles_desc|\n",
      "+-------+---------------+---------------+\n",
      "|  count|      2540672.0|      2540677.0|\n",
      "|   mean|           15.9|            3.0|\n",
      "| stddev|           30.5|            5.3|\n",
      "|    min|            0.0|            0.0|\n",
      "|    max|         9276.7|          900.0|\n",
      "+-------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['trip_miles', 'trip_total']).select('summary', f.bround('trip_total', 1).alias('trip_total_desc'),\n",
    "                                                 f.bround('trip_miles', 1).alias('trip_miles_desc')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№4 Найдите самый НЕ популярный вид оплаты.\n",
    "<br>Подробнее <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.groupBy\">groupBy</a> <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.orderBy\">orderBy</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Way2ride'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('payment_type').agg({'taxi_id':'count'}).orderBy('count(taxi_id)').collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№5 Найдите идентификатор таксиста выполнившего наибольшее число заказов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(taxi_id=316, count=2225)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('taxi_id').count().orderBy('count', ascending=False).collect()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№6 Чему равна средняя цена среди поездок, оплаченных наличными? Ответ округлите до 5 знака.\n",
    "<br> Подробней <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.where\">where</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|payment_type|avg_cash|\n",
      "+------------+--------+\n",
      "|        Cash|12.03526|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('payment_type').agg({'trip_total':'avg'})\\\n",
    ".where(f.col('payment_type')=='Cash')\\\n",
    ".select('payment_type', f.bround('avg(trip_total)', 5).alias('avg_cash')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№7 Сколько таксистов проехало больше 1000 миль за все время выполнения заказов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2860"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy('taxi_id').agg({'trip_miles':'sum'}).where(f.col('sum(trip_miles)')>1000).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№8 Сколько миль проехал пассажир в самой долгой поездке? (Ответ округлите до целого)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(trip_miles=0.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(f.col(\"trip_seconds\").desc()).select('trip_miles').collect()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№9 Каков средний заработок всех таксистов? Ответ округлите до 5-ого знака.\n",
    "<br>Отсеките неизвестные машины (не определенный taxi_id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|bround(avg(sum_total), 5)|\n",
      "+-------------------------+\n",
      "|               8218.85627|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('taxi_id').agg(f.sum('trip_total').alias('sum_total')).filter('taxi_id is not null')\\\n",
    ".select(f.bround(f.avg(f.col('sum_total')),5)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№10 Сколько поездок начиналось в самый загруженный час?\n",
    "<br>Используйте функцию <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.hour\">hour</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(hour(trip_start_timestamp)=18, count=181127)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(hour('trip_start_timestamp')).count().orderBy(f.col('count').desc()).collect()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№11 Сколько поездок началось во второй четверти дня?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|    538737|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(hour('trip_start_timestamp')).count()\\\n",
    ".filter(f.col('hour(trip_start_timestamp)')>=6).filter(f.col('hour(trip_start_timestamp)')<12)\\\n",
    ".select(f.sum('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№12 Найдите топ три даты, в которые было суммарно больше всего чаевых? (Чаевые выдаются после совершения поездки)\n",
    "<br> Ожидаемый формат дат YYYY-MM-DD\n",
    "<br>Вам может понадобится конвертация типов <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column.cast\">cast</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+------------------+\n",
      "|to_date(`trip_end_timestamp`)|         sum(tips)|\n",
      "+-----------------------------+------------------+\n",
      "|                   2016-11-03|110102.37000000013|\n",
      "|                   2016-11-09|106187.87999999986|\n",
      "|                   2016-11-16| 99993.77000000038|\n",
      "+-----------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(f.to_date('trip_end_timestamp')).agg(f.sum('tips')).orderBy(f.col('sum(tips)').desc()).limit(3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№13 Сколько было заказов в дату с наибольшим спросом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-----+\n",
      "|to_date(`trip_start_timestamp`)|count|\n",
      "+-------------------------------+-----+\n",
      "|                     2016-11-03|61259|\n",
      "+-------------------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(f.to_date('trip_start_timestamp')).count().orderBy(f.col('count').desc()).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгрузите данные о марках машин из датасета <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week3/spark-tasks/taxi_cars_data.parquet\">taxi_cars_data.parquet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car = spark.read.option('header', 'true').parquet('taxi_cars_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|taxi_id|          car_model|\n",
      "+-------+-------------------+\n",
      "|   1159|       Toyota Prius|\n",
      "|   7273|Ford Crown Victoria|\n",
      "|   2904|        Honda Civic|\n",
      "|   3210|        Ford Fusion|\n",
      "|   2088|       Toyota Camry|\n",
      "+-------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_car.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№14 Какая марка машины самая распрастранненая среди таксистов?\n",
    "<br>Подробнее <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.split\">split</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| model|\n",
      "+------+\n",
      "|Toyota|\n",
      "|  Ford|\n",
      "| Honda|\n",
      "|  Ford|\n",
      "|Toyota|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_car.select(f.split(f.col('car_model'), ' ', 2).getItem(0).alias('model')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|model|count|\n",
      "+-----+-----+\n",
      "| Ford| 1484|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_car.groupBy(f.split(f.col('car_model'), ' ', 2).getItem(0).alias('model'))\\\n",
    ".count().orderBy(f.col('count').desc()).limit(1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№15 Сколько раз и какая модель машин чаще всего встречается в поездках?\n",
    "<br>Подробнее <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.join\">join</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = df.join(df_car, df.taxi_id==df_car.taxi_id, 'left_outer').drop(df_car.taxi_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|          car_model| count|\n",
      "+-------------------+------+\n",
      "|Ford Crown Victoria|388682|\n",
      "+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ndf.groupBy('car_model')\\\n",
    ".count().orderBy(f.col('count').desc()).limit(1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почувствуй силу сжатия! сохрани DataFrame в csv и сравни размеры файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.coalesce(1).write.option('header', 'true').parquet('taxi.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь загрузите данные из csv и проверьте типы методом printSchema()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- taxi_id: integer (nullable = true)\n",
      " |-- trip_start_timestamp: timestamp (nullable = true)\n",
      " |-- trip_end_timestamp: timestamp (nullable = true)\n",
      " |-- trip_seconds: integer (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- trip_total: double (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- car_model: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option('header', 'true').parquet('taxi.parquet')\n",
    "df. printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забудьте посетить SparkUI и изучить историю ваших задач."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
